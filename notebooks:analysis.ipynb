{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-commerce Product Analysis: SQL + Python\n",
    "\n",
    "##   Overview\n",
    "This notebook performs a comprehensive analysis of the Olist E-commerce dataset. The goal is to extract actionable insights regarding sales trends, product performance, customer behavior, and product associations. \n",
    "\n",
    "**Analysis Steps:**\n",
    "1.  **Setup & Data Loading**: Automatically download the dataset from Kaggle, load it into Pandas DataFrames, and clean it.\n",
    "2.  **Database Integration**: Create a SQLite database and populate it with the cleaned data.\n",
    "3.  **SQL-based Analysis**: Execute pre-written SQL queries to perform initial aggregations (e.g., sales trends, category revenue).\n",
    "4.  **Advanced Python Analysis**: \n",
    "    * Visualize the results from the SQL queries.\n",
    "    * Conduct RFM analysis for customer segmentation.\n",
    "    * Perform Market Basket Analysis to discover product associations.\n",
    "5.  **Insights & Conclusion**: Summarize key findings and provide business recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Setup and Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "\n",
    "# Set plot style\n",
    "sns.set_style('whitegrid')\n",
    "plt.style.use('seaborn-v0_8-deep')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../images', exist_ok=True)\n",
    "\n",
    "print(\"Directories and libraries are set up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Kaggle API\n",
    "# IMPORTANT: Make sure your kaggle.json file is in ~/.kaggle/ or in the project root.\n",
    "import kaggle\n",
    "\n",
    "print(\"Authenticating with Kaggle...\")\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "# Download the dataset\n",
    "dataset = 'olistbr/brazilian-ecommerce'\n",
    "download_path = '../data/'\n",
    "\n",
    "print(f\"Downloading dataset '{dataset}' to '{download_path}'...\")\n",
    "kaggle.api.dataset_download_files(dataset, path=download_path, unzip=True)\n",
    "print(\"Dataset downloaded and unzipped successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Loading, Cleaning, and Database Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets into Pandas DataFrames\n",
    "data_path = '../data/'\n",
    "try:\n",
    "    customers = pd.read_csv(f'{data_path}olist_customers_dataset.csv')\n",
    "    orders = pd.read_csv(f'{data_path}olist_orders_dataset.csv')\n",
    "    order_items = pd.read_csv(f'{data_path}olist_order_items_dataset.csv')\n",
    "    products = pd.read_csv(f'{data_path}olist_products_dataset.csv')\n",
    "    category_translation = pd.read_csv(f'{data_path}product_category_name_translation.csv')\n",
    "    order_payments = pd.read_csv(f'{data_path}olist_order_payments_dataset.csv')\n",
    "    print(\"All CSV files loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading CSV files: {e}. Make sure the download was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Cleaning --- \n",
    "\n",
    "# 1. Convert date columns to datetime objects\n",
    "date_cols = ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
    "for col in date_cols:\n",
    "    orders[col] = pd.to_datetime(orders[col], errors='coerce')\n",
    "\n",
    "# 2. Handle missing values\n",
    "# For simplicity, we'll drop rows with missing critical information like product_id or category.\n",
    "products.dropna(subset=['product_category_name'], inplace=True)\n",
    "\n",
    "# 3. Merge category translation\n",
    "products = products.merge(category_translation, on='product_category_name', how='left')\n",
    "\n",
    "print(\"Data cleaning and preparation complete.\")\n",
    "products.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SQLite database and load the data\n",
    "db_path = '../data/ecommerce.db'\n",
    "engine = create_engine(f'sqlite:///{db_path}')\n",
    "\n",
    "# Load DataFrames into SQL tables\n",
    "customers.to_sql('customers', engine, if_exists='replace', index=False)\n",
    "orders.to_sql('orders', engine, if_exists='replace', index=False)\n",
    "order_items.to_sql('order_items', engine, if_exists='replace', index=False)\n",
    "products.to_sql('products', engine, if_exists='replace', index=False)\n",
    "category_translation.to_sql('product_category_name_translation', engine, if_exists='replace', index=False)\n",
    "order_payments.to_sql('order_payments', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(f\"Database created at '{db_path}' and all tables loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: SQL-based Analysis\n",
    "\n",
    "Now we'll execute the SQL queries from the `sql/` directory to perform our initial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql_query(query_path, db_engine):\n",
    "    \"\"\"Reads a SQL query from a file and executes it using the given database engine.\"\"\"\n",
    "    with open(query_path, 'r') as file:\n",
    "        query = file.read()\n",
    "    return pd.read_sql_query(query, db_engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Sales Trends Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_trends_df = execute_sql_query('../sql/sales_trends.sql', engine)\n",
    "sales_trends_df['sales_month'] = pd.to_datetime(sales_trends_df['sales_month'])\n",
    "sales_trends_df = sales_trends_df.sort_values('sales_month')\n",
    "\n",
    "print(\"Monthly Sales Trends:\")\n",
    "sales_trends_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Sales Trends\n",
    "plt.figure(figsize=(14, 7))\n",
    "sns.lineplot(data=sales_trends_df, x='sales_month', y='monthly_revenue', marker='o')\n",
    "plt.title('Monthly Sales Revenue Trend', fontsize=16)\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Revenue (in R$)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/monthly_sales_revenue.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**: The sales trend shows significant growth over time, with a massive peak in November 2017. This is likely due to Black Friday, indicating a strong seasonal influence on sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Revenue by Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_by_cat_df = execute_sql_query('../sql/revenue_by_category.sql', engine)\n",
    "print(\"Revenue by Category:\")\n",
    "revenue_by_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Top 10 Categories by Revenue\n",
    "top_10_cats = revenue_by_cat_df.nlargest(10, 'total_revenue')\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(data=top_10_cats, y='category', x='total_revenue', palette='viridis', orient='h')\n",
    "plt.title('Top 10 Product Categories by Revenue', fontsize=16)\n",
    "plt.xlabel('Total Revenue (in R$)', fontsize=12)\n",
    "plt.ylabel('Product Category', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../images/top_categories_revenue.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**: `Bed Bath Table`, `Health Beauty`, and `Sports Leisure` are the highest revenue-generating categories. These are key areas to focus on for marketing and inventory management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Top Selling Products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_products_df = execute_sql_query('../sql/top_products.sql', engine)\n",
    "print(\"Top 10 Selling Products by Units:\")\n",
    "top_products_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**: The top-selling products are concentrated in categories like `Bed Bath Table`, `Furniture Decor`, and `Garden Tools`. This reinforces the importance of these categories to the business's overall sales volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Advanced Python Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Customer Segmentation (RFM Analysis)\n",
    "RFM stands for Recency, Frequency, and Monetary value. It's a method used to segment customers based on their purchasing behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the RFM query\n",
    "rfm_df = execute_sql_query('../sql/customer_segmentation.sql', engine)\n",
    "rfm_df.dropna(inplace=True) # Drop customers with no monetary value\n",
    "\n",
    "# Create RFM scores by binning into quantiles\n",
    "rfm_df['R_score'] = pd.qcut(rfm_df['recency'], 4, labels=[4, 3, 2, 1]) # Higher score for lower recency\n",
    "rfm_df['F_score'] = pd.qcut(rfm_df['frequency'].rank(method='first'), 4, labels=[1, 2, 3, 4])\n",
    "rfm_df['M_score'] = pd.qcut(rfm_df['monetary'], 4, labels=[1, 2, 3, 4])\n",
    "\n",
    "# Combine scores\n",
    "rfm_df['RFM_score'] = rfm_df['R_score'].astype(str) + rfm_df['F_score'].astype(str) + rfm_df['M_score'].astype(str)\n",
    "\n",
    "print(\"RFM DataFrame with scores:\")\n",
    "rfm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define customer segments based on RFM scores\n",
    "segment_map = {\n",
    "    r'[3-4][3-4][3-4]': 'Champions',\n",
    "    r'[2-4][3-4][1-4]': 'Loyal Customers',\n",
    "    r'[3-4][1-2][1-4]': 'Potential Loyalists',\n",
    "    r'[3-4][1-1][1-4]': 'New Customers',\n",
    "    r'[2-3][1-2][1-4]': 'Promising',\n",
    "    r'[1-2][2-4][1-4]': 'Customers Needing Attention',\n",
    "    r'[1-2][1-2][2-4]': 'At Risk',\n",
    "    r'[1-2][1-2][1-2]': 'Hibernating'\n",
    "}\n",
    "\n",
    "rfm_df['segment'] = rfm_df['R_score'].astype(str) + rfm_df['F_score'].astype(str)\n",
    "rfm_df['segment'] = rfm_df['segment'].replace(segment_map, regex=True)\n",
    "\n",
    "# For any that didn't match (less common combinations)\n",
    "rfm_df['segment'] = rfm_df['RFM_score'].replace(segment_map, regex=True)\n",
    "\n",
    "segment_counts = rfm_df['segment'].value_counts().reset_index()\n",
    "segment_counts.columns = ['segment', 'count']\n",
    "print(\"Customer Segments:\")\n",
    "segment_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Customer Segments using a Treemap\n",
    "fig = px.treemap(segment_counts,\n",
    "                  path=['segment'],\n",
    "                  values='count',\n",
    "                  color='count',\n",
    "                  color_continuous_scale='Blues',\n",
    "                  title='Customer Segmentation by RFM')\n",
    "fig.update_layout(margin = dict(t=50, l=25, r=25, b=25))\n",
    "fig.write_image(\"../images/rfm_customer_segmentation.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**: The RFM segmentation reveals a large group of `Hibernating` customers. This is a critical insight, pointing to a need for re-engagement campaigns. On the other hand, `Champions` and `Loyal Customers` represent our high-value segments that should be nurtured with loyalty programs and exclusive offers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Market Basket Analysis\n",
    "This analysis helps us understand which products are frequently purchased together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for Market Basket Analysis\n",
    "# We need a transaction-style DataFrame: one row per order, with product categories as columns\n",
    "\n",
    "# Merge order items with products to get category names\n",
    "mba_data = order_items.merge(products[['product_id', 'product_category_name_english']], on='product_id')\n",
    "\n",
    "# Filter for relevant columns and drop missing categories\n",
    "mba_data = mba_data[['order_id', 'product_category_name_english']].dropna()\n",
    "\n",
    "# Create the basket: one-hot encode the data\n",
    "basket = mba_data.groupby(['order_id', 'product_category_name_english'])['product_category_name_english']\\\n",
    "                    .count().unstack().reset_index().fillna(0).set_index('order_id')\n",
    "\n",
    "# Convert counts to binary (either bought or not)\n",
    "def encode_units(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    if x >= 1:\n",
    "        return 1\n",
    "\n",
    "basket_sets = basket.applymap(encode_units)\n",
    "\n",
    "# Remove postage category if it exists as it's not a product\n",
    "if 'portateis_cozinha_e_preparadores_de_alimentos' in basket_sets.columns:\n",
    "    basket_sets.drop('portateis_cozinha_e_preparadores_de_alimentos', axis=1, inplace=True)\n",
    "\n",
    "print(\"Basket prepared for analysis:\")\n",
    "basket_sets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Apriori algorithm to find frequent itemsets\n",
    "frequent_itemsets = apriori(basket_sets, min_support=0.005, use_colnames=True)\n",
    "\n",
    "# Generate association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "\n",
    "# Sort rules by lift and confidence\n",
    "rules = rules.sort_values(['lift', 'confidence'], ascending=[False, False])\n",
    "\n",
    "print(\"Top Product Association Rules:\")\n",
    "rules.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight**: The association rules show strong connections between certain product categories. For example, a high **lift** value between `Computers Accessories` and `Bed Bath Table` suggests that customers buying one are significantly more likely to buy the other than by random chance. This information is gold for:\n",
    "* **Cross-selling**: \"Customers who bought X also bought Y\" recommendations.\n",
    "* **Product Bundling**: Creating attractive packages with associated products.\n",
    "* **Store Layout**: Placing related product categories closer together, both online and offline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Final Conclusion & Business Recommendations\n",
    "\n",
    "This analysis has provided a multi-faceted view of the e-commerce business, yielding several actionable insights:\n",
    "\n",
    "1.  **Focus on Top Categories**: `Bed Bath Table`, `Health Beauty`, and `Sports Leisure` are the cash cows. Marketing budget, inventory, and promotional activities should be prioritized for these categories.\n",
    "\n",
    "2.  **Leverage Seasonality**: The November sales peak (Black Friday) is a critical revenue driver. Planning for this period should start months in advance with targeted campaigns and robust inventory.\n",
    "\n",
    "3.  **Implement a CRM Strategy**: The RFM analysis clearly segments the customer base. A targeted CRM strategy should be developed:\n",
    "    * **Nurture Champions**: Offer loyalty rewards and early access to new products.\n",
    "    * **Re-engage the Hibernating**: Launch win-back campaigns with special discounts to bring dormant customers back.\n",
    "    * **Grow Potential Loyalists**: Encourage repeat purchases with follow-up offers.\n",
    "\n",
    "4.  **Boost Average Order Value (AOV)**: Use the insights from the market basket analysis to implement cross-selling and bundling strategies. Feature associated products on product pages and at checkout to increase the likelihood of add-on purchases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
